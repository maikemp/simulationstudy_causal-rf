\documentclass[11pt, a4paper, leqno]{article}
\usepackage{a4wide}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{float, afterpage, rotating, graphicx}
\usepackage{epstopdf}
\usepackage{longtable, booktabs, tabularx}
\usepackage{fancyvrb, moreverb, relsize}
\usepackage{eurosym, calc}
% \usepackage{chngcntr}
\usepackage{amsmath, amssymb, amsfonts, amsthm, bm, MnSymbol}
\usepackage{caption}
\usepackage{mdwlist}
\usepackage{xfrac}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{minibox}
% \usepackage{pdf14} % Enable for Manuscriptcentral -- can't handle pdf 1.5,
% \usepackage{endfloat} % Enable to move tables / figures to the end. Useful for some submissions.



\usepackage{natbib}
\bibliographystyle{rusnat}




\usepackage[unicode=true]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    anchorcolor=black,
    citecolor=black,,
    filecolor=black,
    menucolor=black,
    runcolor=black,
    urlcolor=black
}


\widowpenalty=10000
\clubpenalty=10000

\setlength{\parskip}{1ex}
\setlength{\parindent}{0ex}
\setstretch{1.5}


\begin{document}

\title{Simulation Study on the Coverage Probabilities of Confidence Intervals for Heterogeneous Treatment Effects Estimated with Causal Random Forests\thanks{Maike Metz-Peeters, Universit√§t Bonn. Email:gi \href{mailto:maike-m-p@web.de}{\nolinkurl{maike-m-p [at] web [dot] de}}.}}

\author{Maike Metz-Peeters}

\date{
{\bf Preliminary -- please do not quote} 
\\[1ex] 
\today
}

\maketitle


\begin{abstract}
	In this simulation study, I investigate the coverage probabilities of the confidence intervals for treatment effects estimated by a nonparametric causal forest developed by \citet{wa18}. I broadly replicate their results and in addition visualize the relationship between the treatment effect estimator and the true treatment effect for a new experimental setup. I cna confirm the author's claim that their estimator performs better in terms of coverage probability and mean squared error most of the time. Furthermore, the bias of the estimator caused by a tendency of the estimator to smoothen bumps in the treatment effect function, can be confirmed.
    
\end{abstract}
\clearpage

\section{Introduction} % (fold)
\label{sec:introduction}

I will first give a brief insight into the method itself. Then I will describe the chosen experimental setups for the simulation study, after which I will present the results. It follows a short conclusion.


The project was programmed with Waf using a template from \citet{GaudeckerEconProjectTemplates}. 


\section{Background} % (fold)
\label{sec:background}
The method described in \citet{wa18} estimates heterogeneous treatment effects in a highly data-driven way using a special form of random forests while still enabling valid statistical inference. This makes it possible to discover even unexpected structures in the data. In the following I will give a short description of the main idea of this method following \citet{wa18} unless stated otherwise. A detailed description of the method will then be given in master thesis. 

For this purpose, the authors assume having at hand \(n\) i.i.d. draws of a feature vector \(X_i \in [0,1]^d\) or following any other density bounded away from 0 and infinity, a treatment indicator \(W_i \in \{0,1\}\), and an outcome \(Y_i \in \mathbb{R}\).
As usual, the treatment effect is the expectation of the difference between the outcome under treatment and without treatment:
\input{formulas/treatment_effect}
where \(Y_i^{(1)}\) denotes the outcome if treatment has taken place and \(Y_i^{(0)}\) is the outcome without treatment. Heterogeneity in the treatment effect depending on the observable variables is allowed for. 
As usually, unconfoundedness is assumed:
\input{formulas/unconfoundedness}
This means that the selection bias into treatment disappears when controlling for observable features, and thus around observations that are "close" in the feature space behave like a randomized experiment. 
Nearest neighbor methods exploit this assumption. As is described by \citet{lj06}, random forests can also be viewed as an adaptively weighted k potential nearest neighbors method. For this reason, a simple k nearest neighbor matching procedure is the used as baseline method.
As explained in detail by \citet{hir03}, if a consistent estimator for the propensity of receiving treatment \(e(x) = \mathbb{E}[W_i|X_i = x]\)  is available, an unbiased estimator for the treatment effect could be obtained employing: 
\input{formulas/propensity_estimation}

Generally, a random regression forest is build by subsampling (originally by bootstrapping) the data and then growing a tree on each subsample by recursively partitioning the data in order to get the best fit according to some splitting criterion \citep[p.~304 ff.]{htf08}. The partitioning is repeated until some stopping criterion is achieved. The idea is that the data points in the terminal nodes of a trees are similar to each other and therefore a constant estimator as a simple average over the observed outcomes suffices:
\input{formulas/tree_estimator}
where \(L(x)\) denotes the leaf containing \(x\).
The variable to split on is selected from a randomly chosen subset of variables only, in order to decorrelate the individual trees to decrease variance. Since individual trees generally exhibit low bias but large variance, averaging at each data point over the estimators of all subsample-trees, can lead to a substantially improved estimator. 
For a comprehensive overview over this method, see \cite[p.~587 ff.]{htf08}.

To obtain an estimator of heterogeneous treatment effects, \cite{wa18} use the following estimator:
\input{formulas/tau_forest_estimator}

Similarly the nearest neighbor matching estimator is given by: 
\input{formulas/tau_knn_estimator}
where \(S_1\) and \(S_0\) represent the k nearest neighbors in the treatment and control group, respectively.   

To prove pointwise consistency and asymptotic Gaussianity for the random forest estimator, in addition to the above mentioned assumptions \cite{wa18} require overlap and, which means that at each data point, the probabilities to receive and not to receive treatment are strictly positive as well as a property they call "honesty". It means that for each observation, the response can only be used either to select the model (that is to place the splits) or to estimate the treatment effect, but not for both. Furthermore, the conditional expectations of the outcome under treatment and without treatment at any data point have to be Lipschitz continuous.
They show that under these conditions, when using the infinitesimal jackknife developed by \cite{e14} to consistently estimate the variance and under some additional regularity assumptions, the treatment effect estimator from such a random forest is pointwise consistent for the true treatment effect and has an asymptotically Gaussian and centered sampling distribution so that asymptotic confidence intervals can be constructed. 

\cite{wa18} develop two algorithms satisfying honesty: the double-sample trees and the propensity trees. The first one is called "Double sample trees" and it splits the available data into two parts. One part (and the features and treatment indicators of the other half) will be used to place the splits for the tree. The second half will be used to estimate the treatment effect per leaf, using function \ref{eq:tau_crf}.
The second algorithm is called "Propensity Trees" and aims at placing the splits uses only the treatment assignment indicator to place its splits and is especially useful if we there is suspected bias due to a variation in the treatment propensity. For more details on these algorithms please see \cite[p.~1232]{wa18}.


\section{Simulation Study} % (fold)
\label{sec:simulation}

For this project, I investigate four different setups. The first one exactly corresponds to the first setup in \cite{wa18}, while the second and the third setup are less computationally expensive versions of the versions in this paper, that is, I reduced the sample size and the number of trees estimated. It is very easy to change to the exact versions of the paper by simply editing the corresponding Json files in the \textit{src/model\_specs}, but time for computation will increase rapidly. As a fourth setup, I chose a treatment effect function that only depends on \(X_1\), and that has two larger bumps. I did this, to illustrate the claim of \cite[p.~1238]{wa18} that random forest approaches tend to flatten the hills and fill up the valleys of the true treatment effect function.

\input{formulas/setup_table.tex} 

The exact parameter values used for this study are summarized in table  \ref{table:setup_table}. 


\input{../../out/tables/coverage_table_setup_1.tex}\label{tab:setup_1}

In table \ref{table:setup_1} to \ref{table:setup_4}it is

\input{../../out/tables/coverage_table_setup_2.tex}

\input{../../out/tables/coverage_table_setup_3.tex}

\input{../../out/tables/coverage_table_setup_4.tex}


{}
\begin{figure}
    \caption{Plot of Micro data for one forest and one testset of Setup 4 with d=3}
    
    \includegraphics[width=\textwidth]{../../out/figures/te_plot_setup_4}

\end{figure}



\section{Conclusion} % (fold)
\label{sec:conclusion}

\pagebreak





\bibliography{refs}



% \appendix

% The chngctr package is needed for the following lines.
% \counterwithin{table}{section}
% \counterwithin{figure}{section}

\end{document}
